{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.io import imread_collection\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from skimage import  io\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\dina\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\dina\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\dina\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\dina\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dina\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dina\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Evaluate(y_test,y_pred):\n",
    "    # Print the evaluation metrics for the dataset.\n",
    "    f1=f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"f1_score:\",f1)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readimgs(path):\n",
    "    file = os.listdir(path)\n",
    "    files = []\n",
    "    for img in file:\n",
    "        fullPath = os.path.join(path, img)\n",
    "        if os.path.isdir(fullPath):\n",
    "            files = files + readimgs(fullPath)\n",
    "        else:\n",
    "            files.append(fullPath)              \n",
    "    return files        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'textures\\training'\n",
    "imgs = readimgs(path)\n",
    "imgs = [io.imread(file) for file in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'textures\\testing'\n",
    "imgs_test = readimgs(path)\n",
    "imgs_test = [io.imread(file) for file in imgs_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img=[]\n",
    "for i in range(len(imgs)):\n",
    "    new_img.append(resize(imgs[i], (32, 32),anti_aliasing=True).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images :  180\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training images : \",len(new_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_test=[]\n",
    "for i in range(len(imgs_test)):\n",
    "    new_img_test.append(resize(imgs_test[i], (32, 32),anti_aliasing=True).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of testing images :  60\n"
     ]
    }
   ],
   "source": [
    "print(\"number of testing images : \",len(new_img_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show(img):\n",
    "    io.imshow(img.reshape(32,32))\n",
    "    plt.show()\n",
    "    \n",
    "show(new_img[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(new_img_test[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labeled the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fiels' name\n",
    "label=[\"canvas1\", \"cushion1\", \"linsseeds1\", \"sand1\",\"seat2\",\"stone1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeld each image with the file name\n",
    "c=[]\n",
    "x=0\n",
    "for j in label:\n",
    "    for i in range(0+x,30+x):\n",
    "        c.append(j)\n",
    "    x=x+30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "x=0\n",
    "for j in label:\n",
    "    for i in range(0+x,10+x):\n",
    "        t.append(j)\n",
    "    x=x+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### train data ########################\n",
    "imageA=[]\n",
    "imageB=[]\n",
    "label=[]\n",
    "for i in range(len(new_img)-1):\n",
    "    for j in range(i+1,len(new_img)):\n",
    "        # save the images in list\n",
    "        imageA.append(new_img[i])\n",
    "        imageB.append(new_img[j])\n",
    "        #if the 2 images have same class. labeled them as 1 if not 0\n",
    "        if(c[i]==c[j]):\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images : 16110\n"
     ]
    }
   ],
   "source": [
    "print(\"number of images :\",len(imageA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### test data ########################\n",
    "\n",
    "imageA_test=[]\n",
    "imageB_test=[]\n",
    "label_test=[]\n",
    "for i in range(len(new_img_test)-1):\n",
    "    for j in range(i+1,len(new_img_test)):\n",
    "        imageA_test.append(new_img_test[i])\n",
    "        imageB_test.append(new_img_test[j])\n",
    "        if(t[i]==t[j]):\n",
    "            label_test.append(1)\n",
    "        else:\n",
    "            label_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images : 1770\n"
     ]
    }
   ],
   "source": [
    "print(\"number of images :\",len(imageA_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concatenate 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### train data ########################\n",
    "\n",
    "concat=[]\n",
    "for i in range(len(imageA)):\n",
    "    concat.append(np.concatenate((imageA[i], imageB[i]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### test data ########################\n",
    "concat_test=[]\n",
    "for i in range(len(imageA_test)):\n",
    "    concat_test.append(np.concatenate((imageA_test[i], imageB_test[i]), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(imageA, imageB):\n",
    "    imageA=np.flip(imageA, (0))\n",
    "    mul = np.multiply(imageA,imageB)\n",
    "    score= sum(mul)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc(imageA, imageB):\n",
    "    mul = np.multiply(imageA,imageB)\n",
    "    score= sum(mul)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd(imageA,imageB):\n",
    "    score = np.sum((np.array(imageA, dtype=np.float32) - np.array(imageB, dtype=np.float32))**2)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function matching Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchingImages( imageA, imageB, method, normalize):\n",
    "    if normalize=='y':\n",
    "        imageA = imageA- np.mean(imageA)/ np.std(imageA)\n",
    "        imageB = imageB- np.mean(imageB)/ np.std(imageB)\n",
    "        \n",
    "    if method == 'cc' :\n",
    "       result=cc(imageA,imageB)\n",
    "\n",
    "    elif method == 'conv':\n",
    "        result=conv(imageA,imageB)\n",
    "\n",
    "    elif method == 'ssd':\n",
    "        #result = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "        result=ssd(imageA,imageB)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame({'imageA':imageA,'imageB':imageB,'concat':concat,'class':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageA</th>\n",
       "      <th>imageB</th>\n",
       "      <th>concat</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>[0.4, 0.4215686274509806, 0.4382352941176472, ...</td>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>[0.4872549019607842, 0.48627450980392156, 0.44...</td>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>[0.5617647058823528, 0.5343137254901961, 0.456...</td>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>[0.45294117647058824, 0.4647058823529412, 0.47...</td>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>[0.519607843137255, 0.4784313725490196, 0.4862...</td>\n",
       "      <td>[0.49607843137254903, 0.5019607843137255, 0.45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              imageA  \\\n",
       "0  [0.49607843137254903, 0.5019607843137255, 0.45...   \n",
       "1  [0.49607843137254903, 0.5019607843137255, 0.45...   \n",
       "2  [0.49607843137254903, 0.5019607843137255, 0.45...   \n",
       "3  [0.49607843137254903, 0.5019607843137255, 0.45...   \n",
       "4  [0.49607843137254903, 0.5019607843137255, 0.45...   \n",
       "\n",
       "                                              imageB  \\\n",
       "0  [0.4, 0.4215686274509806, 0.4382352941176472, ...   \n",
       "1  [0.4872549019607842, 0.48627450980392156, 0.44...   \n",
       "2  [0.5617647058823528, 0.5343137254901961, 0.456...   \n",
       "3  [0.45294117647058824, 0.4647058823529412, 0.47...   \n",
       "4  [0.519607843137255, 0.4784313725490196, 0.4862...   \n",
       "\n",
       "                                              concat  class  \n",
       "0  [0.49607843137254903, 0.5019607843137255, 0.45...      1  \n",
       "1  [0.49607843137254903, 0.5019607843137255, 0.45...      1  \n",
       "2  [0.49607843137254903, 0.5019607843137255, 0.45...      1  \n",
       "3  [0.49607843137254903, 0.5019607843137255, 0.45...      1  \n",
       "4  [0.49607843137254903, 0.5019607843137255, 0.45...      1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13500\n",
       "1     2610\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train and validition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= rus.fit_resample(concat, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.30, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train data *****\n",
      "class 0 : 1827\n",
      "class 1 : 1827\n",
      "the size of train data :  3654\n"
     ]
    }
   ],
   "source": [
    "print('***** train data *****')\n",
    "print(\"class 0 :\",np.shape(np.array(y_train)[np.array(y_train) == 0])[0])\n",
    "print(\"class 1 :\",np.shape(np.array(y_train)[np.array(y_train) == 1])[0])\n",
    "print('the size of train data : ',len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** valid data *****\n",
      "class 0 : 783\n",
      "class 1 : 783\n",
      "the size of valid data :  1566\n"
     ]
    }
   ],
   "source": [
    "print('***** valid data *****')\n",
    "print(\"class 0 :\",np.shape(np.array(y_valid)[np.array(y_valid) == 0])[0])\n",
    "print(\"class 1 :\",np.shape(np.array(y_valid)[np.array(y_valid) == 1])[0])\n",
    "print('the size of valid data : ',len(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep (conc):\n",
    "    middle_index=len(conc[0])// 2\n",
    "    imageA=[]\n",
    "    imageB=[]\n",
    "    for i in conc:\n",
    "        imageA.append(i[:middle_index]) \n",
    "        imageB.append(i[middle_index:])\n",
    "    return imageA , imageB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  operations(imageA , imageB ,method ,norm):\n",
    "    result=[]\n",
    "    for i in range(len(imageA)): \n",
    "        result.append(matchingImages( imageA[i], imageB[i], method,norm))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(X_train,X_valid,method ,norm):\n",
    "    imageA_train , imageB_train= sep (X_train)\n",
    "    train=operations(imageA_train , imageB_train,method ,norm)\n",
    "    threshold=np.mean(train)\n",
    "\n",
    "    imageA_valid , imageB_valid = sep (X_valid)\n",
    "    valid=operations(imageA_valid , imageB_valid,method ,norm)\n",
    "    if method != 'ssd':\n",
    "        for i in range(len(valid)):\n",
    "            if  valid[i]<threshold:\n",
    "                  valid[i]=0  \n",
    "            else :\n",
    "                 valid[i]=1\n",
    "    else :\n",
    "        for i in range(len(valid)):\n",
    "            if  valid[i]>threshold:\n",
    "                  valid[i]=0  \n",
    "            else :\n",
    "                 valid[i]=1\n",
    "        \n",
    "    return valid                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### cc _ y #######################\n",
      "f1_score: 0.4732531328152198\n",
      "Accuracy: 0.4891443167305236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.66      0.56       783\n",
      "           1       0.48      0.32      0.38       783\n",
      "\n",
      "    accuracy                           0.49      1566\n",
      "   macro avg       0.49      0.49      0.47      1566\n",
      "weighted avg       0.49      0.49      0.47      1566\n",
      "\n",
      "####################### cc _ n #######################\n",
      "f1_score: 0.5523479218276905\n",
      "Accuracy: 0.5523627075351213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       783\n",
      "           1       0.55      0.56      0.55       783\n",
      "\n",
      "    accuracy                           0.55      1566\n",
      "   macro avg       0.55      0.55      0.55      1566\n",
      "weighted avg       0.55      0.55      0.55      1566\n",
      "\n",
      "####################### conv _ y #######################\n",
      "f1_score: 0.4732531328152198\n",
      "Accuracy: 0.4891443167305236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.66      0.56       783\n",
      "           1       0.48      0.32      0.38       783\n",
      "\n",
      "    accuracy                           0.49      1566\n",
      "   macro avg       0.49      0.49      0.47      1566\n",
      "weighted avg       0.49      0.49      0.47      1566\n",
      "\n",
      "####################### conv _ n #######################\n",
      "f1_score: 0.5005192688987946\n",
      "Accuracy: 0.5012771392081737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48       783\n",
      "           1       0.50      0.54      0.52       783\n",
      "\n",
      "    accuracy                           0.50      1566\n",
      "   macro avg       0.50      0.50      0.50      1566\n",
      "weighted avg       0.50      0.50      0.50      1566\n",
      "\n",
      "####################### ssd _ y #######################\n",
      "f1_score: 0.7165563656905749\n",
      "Accuracy: 0.7362707535121328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64       783\n",
      "           1       0.65      1.00      0.79       783\n",
      "\n",
      "    accuracy                           0.74      1566\n",
      "   macro avg       0.83      0.74      0.72      1566\n",
      "weighted avg       0.83      0.74      0.72      1566\n",
      "\n",
      "####################### ssd _ n #######################\n",
      "f1_score: 0.4703235294117647\n",
      "Accuracy: 0.47126436781609193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.51      0.49       783\n",
      "           1       0.47      0.43      0.45       783\n",
      "\n",
      "    accuracy                           0.47      1566\n",
      "   macro avg       0.47      0.47      0.47      1566\n",
      "weighted avg       0.47      0.47      0.47      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods=['cc','conv','ssd']\n",
    "normaliztion =['y','n']\n",
    "classifiers=[]\n",
    "f1=[]\n",
    "for method in methods :\n",
    "    for norm in normaliztion:\n",
    "        classifiers.append(method+\"_\"+norm)\n",
    "        print('#######################',method,\"_\",norm,'#######################')\n",
    "        predict=report(X_train,X_valid,method ,norm)\n",
    "        f1.append(model_Evaluate(y_valid,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the best classifier according to f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best classifier ssd_y  with f1 score : 0.7165563656905749\n"
     ]
    }
   ],
   "source": [
    "best=np.argmax(f1)\n",
    "print('the best classifier',classifiers[best],\" with f1 score :\",f1[best])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dina\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=1, solver='sgd', warm_start='true')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "\n",
    "nn_clf =   MLPClassifier(max_iter=1,warm_start='true',solver='sgd')\n",
    "nn_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=nn_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.40397625068432447\n",
      "Accuracy: 0.5068418171866448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.09      0.16      1827\n",
      "           1       0.50      0.92      0.65      1827\n",
      "\n",
      "    accuracy                           0.51      3654\n",
      "   macro avg       0.52      0.51      0.40      3654\n",
      "weighted avg       0.52      0.51      0.40      3654\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40397625068432447"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Evaluate(y_train,pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model didn't train well on the data train ..it suffers from underfitting .. i increase  the complexty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.52503943443298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dina\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timee=time.time()\n",
    "nn_clf =   MLPClassifier(max_iter=100)\n",
    "nn_clf.fit(X_train,y_train)\n",
    "timee=time.time()-timee\n",
    "print(timee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train=nn_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.8131623146000366\n",
      "Accuracy: 0.8139025725232621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82      1827\n",
      "           1       0.86      0.75      0.80      1827\n",
      "\n",
      "    accuracy                           0.81      3654\n",
      "   macro avg       0.82      0.81      0.81      3654\n",
      "weighted avg       0.82      0.81      0.81      3654\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8131623146000366"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Evaluate(y_train,pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model didn't train very well. but it's fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=nn_clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7581268485047651\n",
      "Accuracy: 0.7598978288633461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78       783\n",
      "           1       0.81      0.67      0.74       783\n",
      "\n",
      "    accuracy                           0.76      1566\n",
      "   macro avg       0.77      0.76      0.76      1566\n",
      "weighted avg       0.77      0.76      0.76      1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7581268485047651"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Evaluate(y_valid,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032913923263549805\n"
     ]
    }
   ],
   "source": [
    "timee=time.time()\n",
    "pred_mlp=nn_clf.predict(concat_test)\n",
    "timee=time.time()-timee\n",
    "print(timee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is faster it predict the test in (0.03) s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.6066318617093017\n",
      "Accuracy: 0.5423728813559322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.56      0.68      1500\n",
      "           1       0.15      0.43      0.22       270\n",
      "\n",
      "    accuracy                           0.54      1770\n",
      "   macro avg       0.50      0.50      0.45      1770\n",
      "weighted avg       0.74      0.54      0.61      1770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6066318617093017"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Evaluate(label_test,pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No efforts in the train but it took 34 s because it build on 100 interations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regarding to test report : it get 0.68 f1-score for class 0 and 0.22 for class 1. that mean it can't classfy it. so, i don't think that it is generalized. the f1_score decrease each time the model see the unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robustness : the model has a ratio of error with train data , increased in the validation and be high with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1421494483947754\n"
     ]
    }
   ],
   "source": [
    "timee=time.time()\n",
    "pred_classifier=report(X_train,concat_test,'ssd' ,'y')\n",
    "timee=time.time()-timee\n",
    "print(timee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it took (3)s to predict the test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.5741469934092844\n",
      "Accuracy: 0.5214689265536723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.44      0.61      1500\n",
      "           1       0.24      0.99      0.39       270\n",
      "\n",
      "    accuracy                           0.52      1770\n",
      "   macro avg       0.62      0.71      0.50      1770\n",
      "weighted avg       0.88      0.52      0.57      1770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5741469934092844"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Evaluate(label_test,pred_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No efforts in the train but the training . but the threashold depends on my decision to choose the best approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regarding to test report : it get 0.61 f1-score for class 0 and 0.39 for class 1. that mean it can't classfy it. so, i don't think that it is generalized. the f1_score decrease each time the model see the unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robustness : the model has a ratio of error with train data , increased in the validation and be high with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import filters\n",
    "X_train_filtered = skimage.filters.gaussian(np.asarray( X_train))\n",
    "X_test_filtered = skimage.filters.gaussian(np.asarray( concat_test))\n",
    "X_valid= skimage.filters.gaussian(np.asarray( X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = skimage.filters.sobel(np.asarray( X_train))\n",
    "X_test_filtered = skimage.filters.sobel(np.asarray( concat_test))\n",
    "X_valid= skimage.filters.sobel(np.asarray( X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=32)\n",
    "pca = pca.fit(X_train_filtered)\n",
    "X_train_filtered_scaled=pca.transform(X_train_filtered)\n",
    "X_test_filtered_scaled=pca.transform(X_test_filtered)\n",
    "X_valid=pca.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dina\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_clf2 =   MLPClassifier(max_iter=100)\n",
    "nn_clf2.fit(X_train_filtered_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7716265815230364\n",
      "Accuracy: 0.7389830508474576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83      1500\n",
      "           1       0.34      0.72      0.46       270\n",
      "\n",
      "    accuracy                           0.74      1770\n",
      "   macro avg       0.64      0.73      0.64      1770\n",
      "weighted avg       0.85      0.74      0.77      1770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7716265815230364"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=nn_clf2.predict(X_test_filtered_scaled)\n",
    "model_Evaluate(label_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first : i need to remove noise and detail so i used Gaussian filter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second : i need to make fillter to make edge detection so i used Sobel filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this appoach make the f1_score: 0.77  instead of 0.60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
